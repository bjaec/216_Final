{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db252578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in /Users/darrenwu/opt/anaconda3/lib/python3.9/site-packages (4.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "# Detect encoding for the kaggle datasets\n",
    "!pip install chardet\n",
    "import chardet\n",
    "with open('2021-2022.csv', 'rb') as f:\n",
    "    encoding = chardet.detect(f.read())['encoding']\n",
    "encoding\n",
    "nba_2022_2023_df = pd.read_csv('2022-2023.csv', encoding=encoding, sep=';')\n",
    "nba_2021_2022_df = pd.read_csv('2021-2022.csv', encoding=encoding, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1df0821e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>age</th>\n",
       "      <th>player_height</th>\n",
       "      <th>player_weight</th>\n",
       "      <th>college</th>\n",
       "      <th>country</th>\n",
       "      <th>draft_year</th>\n",
       "      <th>draft_round</th>\n",
       "      <th>draft_number</th>\n",
       "      <th>gp</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>net_rating</th>\n",
       "      <th>oreb_pct</th>\n",
       "      <th>dreb_pct</th>\n",
       "      <th>usg_pct</th>\n",
       "      <th>ts_pct</th>\n",
       "      <th>ast_pct</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12300</th>\n",
       "      <td>Tobias Harris</td>\n",
       "      <td>PHI</td>\n",
       "      <td>29.0</td>\n",
       "      <td>200.66</td>\n",
       "      <td>102.511792</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>USA</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>73</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.158</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12301</th>\n",
       "      <td>Tomas Satoransky</td>\n",
       "      <td>WAS</td>\n",
       "      <td>30.0</td>\n",
       "      <td>200.66</td>\n",
       "      <td>95.254320</td>\n",
       "      <td>None</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>55</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.285</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12302</th>\n",
       "      <td>Tony Bradley</td>\n",
       "      <td>CHI</td>\n",
       "      <td>24.0</td>\n",
       "      <td>208.28</td>\n",
       "      <td>112.490816</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>USA</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.065</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12303</th>\n",
       "      <td>Tony Snell</td>\n",
       "      <td>NOP</td>\n",
       "      <td>30.0</td>\n",
       "      <td>198.12</td>\n",
       "      <td>96.615096</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>USA</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12304</th>\n",
       "      <td>Terry Rozier</td>\n",
       "      <td>CHA</td>\n",
       "      <td>28.0</td>\n",
       "      <td>185.42</td>\n",
       "      <td>86.182480</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>USA</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>73</td>\n",
       "      <td>19.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.197</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            player_name team_abbreviation   age  player_height  player_weight  \\\n",
       "12300     Tobias Harris               PHI  29.0         200.66     102.511792   \n",
       "12301  Tomas Satoransky               WAS  30.0         200.66      95.254320   \n",
       "12302      Tony Bradley               CHI  24.0         208.28     112.490816   \n",
       "12303        Tony Snell               NOP  30.0         198.12      96.615096   \n",
       "12304      Terry Rozier               CHA  28.0         185.42      86.182480   \n",
       "\n",
       "              college         country draft_year draft_round draft_number  gp  \\\n",
       "12300       Tennessee             USA       2011           1           19  73   \n",
       "12301            None  Czech Republic       2012           2           32  55   \n",
       "12302  North Carolina             USA       2017           1           28  55   \n",
       "12303      New Mexico             USA       2013           1           20  53   \n",
       "12304      Louisville             USA       2015           1           16  73   \n",
       "\n",
       "        pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  ts_pct  \\\n",
       "12300  17.2  6.8  3.5         3.2     0.032     0.164    0.214   0.566   \n",
       "12301   3.6  2.3  3.3        -8.0     0.029     0.110    0.124   0.461   \n",
       "12302   3.0  3.4  0.5         5.2     0.123     0.196    0.128   0.600   \n",
       "12303   3.5  1.9  0.5        -7.8     0.018     0.107    0.099   0.541   \n",
       "12304  19.3  4.3  4.5         1.4     0.021     0.101    0.227   0.566   \n",
       "\n",
       "       ast_pct   season  \n",
       "12300    0.158  2021-22  \n",
       "12301    0.285  2021-22  \n",
       "12302    0.065  2021-22  \n",
       "12303    0.047  2021-22  \n",
       "12304    0.197  2021-22  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_seasons.csv')\n",
    "df.drop(columns=df.columns[0], inplace=True)\n",
    "df = df[df['season'].isin(['2019-20', '2020-21', '2021-22'])]\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "884d8131",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_feature(column,X_train,y_train,X_test,y_test):\n",
    "    df_feature_train = X_train.sort_values([column],ascending=[True]).groupby(column).apply(lambda df: pd.DataFrame(np.array([[df.age.values[-1], np.mean(df.gp.values), np.mean(df.pts.values), df.pts.values[-1], df.pts.values[-2], np.mean(df.net_rating.values), np.mean(df.ts_pct.values), np.mean(df.usg_pct.values), df['season_index'].values[-1]]])))\n",
    "    x_feature_train = df_feature_train.values\n",
    "    labels_train = y_train.sort_values([column],ascending=[True]).pts.values\n",
    "\n",
    "    df_feature_test = X_test.sort_values([column],ascending=[True]).groupby(column).apply(lambda df: pd.DataFrame(np.array([[df.age.values[-1], np.mean(df.gp.values), np.mean(df.pts.values), df.pts.values[-1], df.pts.values[-2], np.mean(df.net_rating.values), np.mean(df.ts_pct.values), np.mean(df.usg_pct.values), df['season_index'].values[-1]]])))\n",
    "    x_feature_test = df_feature_test.values\n",
    "    labels_test = y_test.sort_values([column],ascending=[True]).pts.values\n",
    "    return x_feature_train,labels_train,x_feature_test,labels_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e4a9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataframe, augment_data, minimum_records=3, segment_length=5):\n",
    "    # Getting unique player info and assigning IDs\n",
    "    player_unique_values = dataframe[[\"player_name\", \"player_height\", \"player_weight\"]].drop_duplicates()\n",
    "    player_unique_values = player_unique_values.reset_index(drop=True)\n",
    "    player_unique_values.reset_index(inplace=True)\n",
    "    player_unique_values.rename(columns={\"index\": \"PlayerID\"}, inplace=True)\n",
    "    \n",
    "    # Merging to get a combined dataset and dropping some unnecessary columns\n",
    "    combined_data = pd.merge(player_unique_values, dataframe, on=[\"player_name\", \"player_height\", \"player_weight\"])\n",
    "    combined_data.drop(columns=[\"player_name\", \"player_height\", \"player_weight\", \"draft_year\", \"draft_round\", \"draft_number\"], inplace=True)\n",
    "    combined_data.drop(columns=[\"team_abbreviation\", \"college\", \"country\"], inplace=True)\n",
    "    \n",
    "    # Filtering players with enough records and sorting\n",
    "    grouped_data = combined_data.groupby('PlayerID').filter(lambda x: len(x) >= minimum_records)\n",
    "    grouped_data.sort_values(by=[\"PlayerID\", \"season\"], ascending=[True, True])\n",
    "    grouped_data.drop(columns=[\"season\"], inplace=True)\n",
    "    \n",
    "    # Adding season index and total seasons per player\n",
    "    grouped_data[\"season_index\"] = grouped_data.groupby(\"PlayerID\").cumcount() + 1\n",
    "    grouped_data[\"seasons_total\"] = grouped_data.groupby(\"PlayerID\")[\"PlayerID\"].transform(\"count\")\n",
    "    final_dataset = grouped_data.reset_index(drop=True)\n",
    "    \n",
    "    # If augmenting data, create segments for each player\n",
    "    if augment_data:\n",
    "        data_segments = []\n",
    "        segment_counter = 0\n",
    "        for player_id, data_group in final_dataset.groupby(\"PlayerID\"):\n",
    "            group_length = len(data_group)\n",
    "            data_group = data_group.reset_index(drop=True)\n",
    "            if group_length > segment_length:\n",
    "                for i in range(group_length-segment_length+1):\n",
    "                    data_segment = data_group.loc[i:i+segment_length-1].copy()\n",
    "                    data_segment[\"segment_id\"] = segment_counter\n",
    "                    data_segments.append(data_segment)\n",
    "                    segment_counter += 1\n",
    "            else:       \n",
    "                data_group[\"segment_id\"] = segment_counter\n",
    "                data_segments.append(data_group)\n",
    "                segment_counter += 1\n",
    "        final_dataset = pd.concat(data_segments).reset_index(drop=True)\n",
    "        identifier_column = \"segment_id\"\n",
    "    else:\n",
    "        identifier_column = \"PlayerID\"\n",
    "    \n",
    "    # Splitting dataset into training and testing\n",
    "    split_ratio = 0.8\n",
    "    ids = final_dataset[[identifier_column]].drop_duplicates().values.flatten()\n",
    "    total_ids = len(ids)\n",
    "    np.random.shuffle(ids)\n",
    "    training_ids = ids[:int(total_ids * split_ratio)]\n",
    "    testing_ids = ids[int(total_ids * split_ratio):]\n",
    "    training_dataset = pd.concat([final_dataset[final_dataset[identifier_column] == id] for id in training_ids])\n",
    "    testing_dataset = pd.concat([final_dataset[final_dataset[identifier_column] == id] for id in testing_ids])\n",
    "    training_dataset.to_csv(f'./dataset/training_dataset_{identifier_column}.csv', index=False)\n",
    "    testing_dataset.to_csv(f'./dataset/testing_dataset_{identifier_column}.csv', index=False)\n",
    "    \n",
    "    # Reading back the split datasets\n",
    "    training_data = pd.read_csv(f\"./dataset/training_dataset_{identifier_column}.csv\", index_col=False)\n",
    "    testing_data = pd.read_csv(f\"./dataset/testing_dataset_{identifier_column}.csv\", index_col=False)\n",
    "    \n",
    "    # Preparing features and labels for training and testing\n",
    "    training_features = training_data.groupby(identifier_column).apply(lambda x: pd.DataFrame(x[0:-1])).reset_index(drop=True)\n",
    "    training_labels = training_data.groupby(identifier_column).apply(lambda x: pd.DataFrame(x[len(x)-1:len(x)])).reset_index(drop=True)\n",
    "    \n",
    "    testing_features = testing_data.groupby(identifier_column).apply(lambda x: pd.DataFrame(x[0:-1])).reset_index(drop=True)\n",
    "    testing_labels = testing_data.groupby(identifier_column).apply(lambda x: pd.DataFrame(x[len(x)-1:len(x)])).reset_index(drop=True)\n",
    "    \n",
    "    # Extracting features and labels\n",
    "    features_train, labels_train, features_test, labels_test = extract_feature(identifier_column, training_features, training_labels, testing_features, testing_labels)\n",
    "    \n",
    "    # Scaling the features\n",
    "    data_scaler = StandardScaler()\n",
    "    data_scaler.fit(features_train)\n",
    "    features_train_scaled = data_scaler.transform(features_train)\n",
    "    features_test_scaled = data_scaler.transform(features_test)\n",
    "    return features_train_scaled, labels_train, features_test_scaled, labels_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7dfe9bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['player_name', 'player_height', 'player_weight'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVR\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Preprocess the data to get training and testing sets\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m features_train, targets_train, features_test, targets_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize the Linear Regression model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(dataframe, augment_data, minimum_records, segment_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(dataframe, augment_data, minimum_records\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, segment_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     player_unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplayer_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplayer_height\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplayer_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m      3\u001b[0m     player_unique_values \u001b[38;5;241m=\u001b[39m player_unique_values\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     player_unique_values\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3030\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3029\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3030\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3032\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1266\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1264\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_missing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1308\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m   1307\u001b[0m     axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1310\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m# We (temporarily) allow for some missing keys with .loc, except in\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;66;03m# some cases (e.g. setting) in which \"raise_missing\" will be False\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['player_name', 'player_height', 'player_weight'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for linear regression, metrics, and preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "df = pd.read_csv('all_seasons.csv')\n",
    "# Preprocess the data to get training and testing sets\n",
    "features_train, targets_train, features_test, targets_test = preprocess_data(df, 0, segment_length=6)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model with the training data\n",
    "linear_model.fit(features_train, targets_train)\n",
    "\n",
    "# Make predictions on the testing and training datasets\n",
    "predictions_test_linear = linear_model.predict(features_test)\n",
    "predictions_train_linear = linear_model.predict(features_train)\n",
    "\n",
    "# Calculate the Mean Squared Error for both testing and training datasets\n",
    "mse_test_linear = mean_squared_error(targets_test, predictions_test_linear)\n",
    "mse_train_linear = mean_squared_error(targets_train, predictions_train_linear)\n",
    "\n",
    "# Print the MSE for both testing and training to evaluate the model\n",
    "print(mse_test_linear)\n",
    "print(mse_train_linear)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"./dataset/training_dataset_PlayerID.csv\")\n",
    "\n",
    "# Plotting Age Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['age'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Age Distribution of Players')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Players')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "# Plotting Points per Game\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['pts'], bins=20, color='orange', edgecolor='black')\n",
    "plt.title('Points per Game Distribution')\n",
    "plt.xlabel('Points per Game')\n",
    "plt.ylabel('Number of Players')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "# Relationship between Age and Points per Game\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['age'], df['pts'], color='green', alpha=0.5)\n",
    "plt.title('Age vs. Points per Game')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Points per Game')\n",
    "plt.grid(True)\n",
    "\n",
    "# Average Rebounds per Game by Season\n",
    "rebounds_by_season = df.groupby('season_index')['reb'].mean()\n",
    "plt.figure(figsize=(10, 6))\n",
    "rebounds_by_season.plot(kind='bar', color='purple')\n",
    "plt.title('Average Rebounds per Game by Season')\n",
    "plt.xlabel('Season Index')\n",
    "plt.ylabel('Average Rebounds per Game')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
